---
permalink: /
title: ""
excerpt: "Changdae Oh, UW-Madison"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

I am a Ph.D. student in the Department of Computer Sciences at the University of Wisconsin--Madison, advised by Prof. <a href="https://pages.cs.wisc.edu/~sharonli/" style="color: #009B8B; text-decoration:none">**Sharon Li**</a>, and an incoming intern at Meta Superintelligence Labs. Prior to my Ph.D., I earned my M.S. degree in AI from the University of Seoul, where I was advised by Prof. <a href="https://scholar.google.com/citations?user=HWxRii4AAAAJ&hl=ko&oi=ao" style="color: #009B8B; text-decoration:none">**Kyungwoo Song**</a> and Prof. <a href="https://scholar.google.com/citations?user=wc_MQkoAAAAJ&hl=ko&oi=ao" style="color: #009B8B; text-decoration:none">**Jiyoung Jung**</a>. I also had the opportunity to work with <a href="https://zhiqic.github.io/homepage/index.html" style="color: #009B8B; text-decoration:none">**Zhi-Qi Cheng**</a>, <a href="https://scholar.google.co.uk/citations?user=Py54GcEAAAAJ&hl=en" style="color: #009B8B; text-decoration:none">**Alexander Hauptmann**</a>, and <a href="https://www.cs.cmu.edu/~dmortens/" style="color: #009B8B; text-decoration:none">**David Mortensen**</a> during a visiting period at Carnegie Mellon University, and with <a href="https://scholar.google.com/citations?user=jcP7m1QAAAAJ&hl=en" style="color: #009B8B; text-decoration:none">**Dongyoon Han**</a> and <a href="https://scholar.google.com/citations?user=o0qtjzYAAAAJ&hl=en" style="color: #009B8B; text-decoration:none">**Sangdoo Yun**</a> during my internship at NAVER AI Lab.

I am broadly interested in machine learning fundamentals and trustworthy AI. Recently, I have been focusing on understanding and improving the robustness of multimodal LLMs under distribution shifts and uncertainty quantification of LLM agents.
 

## News
Feb. 2026, Will be interning for <a href="https://ai.meta.com/" style="color: #009B8B; text-decoration:none">**Meta Superintelligence Labs (PAR Team)**</a> this summer at Menlo Park, CA! \\
Jan. 2026, Start collaboration with <a href="https://www.anl.gov/" style="color: #009B8B; text-decoration:none">**Argonne National Laboratory**</a> as a Visiting Student-Subcontractor! \\
Jan. 2026, Three papers got accepted to <a href="https://iclr.cc/" style="color: #009B8B; text-decoration:none">**ICLR 2026**</a> with one <a href="https://openreview.net/forum?id=A4Us8jxVGq" style="color: #009B8B; text-decoration:none">Oral presentation</a>!
<!-- Sep 2025, Our <a href="https://arxiv.org/abs/2505.13946" style="color: #009B8B; text-decoration: none;">**Vittle**</a> paper got accepted to <a href="https://neurips.cc/" style="color: #009B8B; text-decoration:none">**NeurIPS 2025**</a> \\
Jun 2025, Our <a href="https://arxiv.org/abs/2505.13946" style="color: #009B8B; text-decoration: none;">**Vittle**</a> paper got accepted to <a href="https://icml.cc/virtual/2025/workshop/39972" style="color: #009B8B; text-decoration:none">**ICML 2025 R2-FM workshop**</a> as an **Oral presentation** (6 out of 176)! \\
May 2025, Selected as a **Top Reviewer** at <a href="https://icml.cc/" style="color: #009B8B; text-decoration:none">**ICML 2025**</a>! \\
May 2025, Our <a href="https://www.sciencedirect.com/science/article/pii/S0031320325005497" style="color: #009B8B; text-decoration: none;">**Graph Perceiver IO**</a> paper got accepted to <a href="https://www.sciencedirect.com/journal/pattern-recognition" style="color: #009B8B; text-decoration:none">**Pattern Recognition**</a>! \\
May 2025, Our <a href="https://arxiv.org/abs/2502.00577" style="color: #009B8B; text-decoration: none;">**UnderstandingMLLM-DistShift**</a> paper got accepted to <a href="https://icml.cc/" style="color: #009B8B; text-decoration:none">**ICML 2025**</a>! \\
Jan 2025, Our <a href="https://arxiv.org/abs/2410.03782" style="color: #009B8B; text-decoration: none;">**DaWin**</a> paper got accepted to <a href="https://iclr.cc/" style="color: #009B8B; text-decoration:none">**ICLR 2025**</a>! \\
Sep 2024, Our <a href="https://arxiv.org/abs/2311.01723" style="color: #009B8B; text-decoration: none;">**CaRot**</a> paper got accepted to <a href="https://neurips/" style="color: #009B8B; text-decoration:none">**NeurIPS 2024**</a>! \\
Aug 2024, Join <a href="https://www.cs.wisc.edu/" style="color: #009B8B; text-decoration:none">**UW-Madison CS**</a> as a PhD student! -->


## Selected Publications and Preprints
(* denotes equal contribution) \\
Refer to the <a href="https://scholar.google.co.kr/citations?user=7oAZaVcAAAAJ" style="color: #009B8B; text-decoration:none">**Google Scholar**</a> and <a href="https://www.overleaf.com/read/vxmyrcmshwqk#2ae4b1" style="color: #009B8B; text-decoration:none">**CV**</a> for the full publication list.

- **Understanding Language Prior of LVLMs by Contrasting Chain-of-Embedding** \\
Lin Long\*, <u>Changdae Oh</u>\*, Seongheon Park, Sharon Li \\
<a href="https://arxiv.org/abs/2509.23050" style="color: #009B8B; text-decoration: none;">[paper]</a> <a href="https://github.com/deeplearning-wisc/understanding_lp" style="color: #009B8B; text-decoration: none;">[code]</a> \\
<span style="color:darkred">**ICLR**</span> 2026

- **How Do Transformers Learn to Associate Tokens: Gradient Leading Terms Bring Mechanistic Interpretability** \\
Shawn Im, <u>Changdae Oh</u>, Zhen Fang, Sharon Li \\
<a href="https://arxiv.org/pdf/2601.19208" style="color: #009B8B; text-decoration: none;">[paper]</a> <a href="https://github.com/deeplearning-wisc/attn-dynamics-basis" style="color: #009B8B; text-decoration: none;">[code]</a> \\
<span style="color:darkred">**ICLR**</span> 2026 **(Oral Presentation)**

- **General Exploratory Bonus for Optimistic Exploration in RLHF** \\
Wendi Li, <u>Changdae Oh</u>, Sharon Li \\
<a href="https://arxiv.org/pdf/2510.03269" style="color: #009B8B; text-decoration: none;">[paper]</a> <a href="https://github.com/WindyLee0822/GEB" style="color: #009B8B; text-decoration: none;">[code]</a> \\
<span style="color:darkred">**ICLR**</span> 2026 \\
NeurIPS 2025, Workshop on Socially Responsible and Trustworthy Foundation Models (**Oral Presentation; 9/136=6.6%**)

- **Visual Instruction Bottleneck Tuning** \\
<u>Changdae Oh</u>, Jiatong Li, Shawn Im, Sharon Li \\
<a href="https://arxiv.org/abs/2505.13946" style="color: #009B8B; text-decoration: none;">[paper]</a> <a href="https://github.com/deeplearning-wisc/vittle" style="color: #009B8B; text-decoration: none;">[code]</a> \\
<span style="color:darkred">**NeurIPS**</span> 2025 \\
ICML 2025, Workshop on Reliable and Responsible Foundation Models (**Oral Presentation; 6/176=3.4%**)

- **Understanding Multimodal LLMs Under Distribution Shifts: An Information-Theoretic Approach** \\
<u>Changdae Oh</u>, Zhen Fang, Shawn Im, Xuefeng Du, Yixuan Li \\
<a href="https://arxiv.org/abs/2502.00577" style="color: #009B8B; text-decoration: none;">[paper]</a> <a href="https://github.com/deeplearning-wisc/mllmshift-emi" style="color: #009B8B; text-decoration: none;">[code]</a> \\
<span style="color:darkred">**ICML**</span> 2025 \\
ICLR 2025, QUESTION Workshop (**Oral Presentation**)

- **DaWin: Training-free Dynamic Weight Interpolation for Robust Adaptation** \\
<a href="https://arxiv.org/abs/2410.03782" style="color: #009B8B; text-decoration: none;">[paper]</a><a href="https://github.com/naver-ai/dawin" style="color: #009B8B; text-decoration: none;">[code]</a> \\
<u>Changdae Oh</u>, Yixuan Li, Kyungwoo Song, Sangdoo Yun, Dongyoon Han \\
<span style="color:darkred">**ICLR**</span> 2025 \\
NeurIPS 2024, Workshop on Adaptive Foundation Models

- **Towards Calibrated Robust Fine-Tuning of Vision-Language Models** \\
<u>Changdae Oh</u>\*, Hyesu Lim\*, Mijoo Kim, Dongyoon Han, Sangdoo Yun, Jaegul Choo, Alexander Hauptmann, Zhi-Qi Cheng, Kyungwoo Song \\
<a href="https://arxiv.org/abs/2311.01723" style="color: #009B8B; text-decoration: none;">[paper]</a> <a href="https://github.com/MLAI-Yonsei/CaRot" style="color: #009B8B; text-decoration: none;">[code]</a> \\
<span style="color:darkred">**NeurIPS**</span> 2024 \\
NeurIPS 2023, Workshop on Distribution Shifts

<!-- - **TC-BERT: Large-scale Language Model for Korean Technology Documents** \\
<a href="https://link.springer.com/article/10.1007/s11227-024-06597-6" style="color: #009B8B; text-decoration: none;">[paper]</a> <a href="https://github.com/MLAI-Yonsei/TC-BERT" style="color: #009B8B; text-decoration: none;">[code]</a> \\
Taero Kim\*, <u>Changdae Oh</u>\*, Hyeji Hwang\*, Eunkyeong Lee, Yewon Kim, Yunjeong Choi, Sungjin Kim, Hosik Choi, Kyungwoo Song \\
<span style="color:#3700FF">**The Journal of Supercomputing**</span> 2024

- **Mitigating the Linguistic Gap with Phonemic Representations for Robust Cross-lingual Transfer** \\
<a href="https://arxiv.org/abs/2402.14279" style="color: #009B8B; text-decoration: none;">[paper]</a> \\
Haeji Jung, <u>Changdae Oh</u>, Jooeon Kang, Jimin Sohn, Kyungwoo Song, Jinkyu Kim, David R. Mortensen \\
EMNLP 2024, Multilingual Representation Learning Workshop

- **Perturb-and-Compare Approach for Detecting Out-of-Distribution Samples in Constrained Access Environments** \\
Hee-young Lee\*, Hoyoon Byun\*, <u>Changdae Oh</u>, JinYeong Bak, Kyungwoo Song \\
<a href="https://arxiv.org/pdf/2408.10107" style="color: #009B8B; text-decoration: none;">[paper]</a> \\
<span style="color:darkred">**ECAI**</span> 2024
<span style="color:red">_Oral presentation_</span>

- **First Step for Theoretical and Practical Foundations of Robust Visual Prompting** \\
Gyeongdeok Seo\*, <u>Changdae Oh</u>\*, Kyungwoo Song \\
IJCAI 2024, The Trustworthy AI Workshop

- **Language Model-guided Student Performance Prediction with Multimodal Auxiliary Information** \\
<u>Changdae Oh</u>, Minhoi Park, Sungjun Lim, Kyungwoo Song \\
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417424008261" style="color: #009B8B; text-decoration: none;">[paper]</a> <a href="https://github.com/changdaeoh/LMgMF/tree/main" style="color: #009B8B; text-decoration: none;">[code]</a> \\
<span style="color:#3700FF">**Expert Systems with Applications**</span> 2024

- **Bibimbap: Pre-trained Models Ensemble for Domain Generalization** \\
Jinho Kang, Taero Kim, Yewon Kim, <u>Changdae Oh</u>, Jiyoung Jung, Rakwoo Chang, Kyungwoo Song \\
<a href="https://www.sciencedirect.com/science/article/pii/S0031320324001420" style="color: #009B8B; text-decoration: none;">[paper]</a> <a href="https://github.com/bubble3jh/bibimbap_ensemble/tree/main" style="color: #009B8B; text-decoration: none;">[code]</a> \\
<span style="color:#3700FF">**Pattern Recognition**</span> 2024

- **Towards Calibrated Robust Fine-Tuning of Vision-Language Models** \\
<u>Changdae Oh</u>, Mijoo Kim, Hyesu Lim, Junhyeok Park, Euiseog Jeong, Zhi-Qi Cheng, Kyungwoo Song \\
<a href="https://openreview.net/forum?id=S9h0eLl71q&referrer=%5Bthe%20profile%20of%20Changdae%20Oh%5D(%2Fprofile%3Fid%3D~Changdae_Oh1)" style="color: #009B8B; text-decoration: none;">[paper]</a>  \\
NeurIPS 2023, Workshop on Distribution Shifts -->

- **Geodesic Multi-Modal Mixup for Robust Fine-tuning** \\
<u>Changdae Oh</u>\*, Junhyuk So\*, YongTaek Lim, Hoyoon Byun, Minchul Shin, Jong-June Jeon, Kyungwoo Song \\
<a href="https://arxiv.org/abs/2203.03897" style="color: #009B8B; text-decoration: none;">[paper]</a> <a href="https://github.com/changdaeoh/multimodal-mixup" style="color: #009B8B; text-decoration: none;">[code]</a> \\
<span style="color:darkred">**NeurIPS**</span> 2023

<!-- - **Robust Contrastive Learning with Dynamic Mixed Margin** \\
<a href="https://ieeexplore.ieee.org/abstract/document/10154052" style="color: #009B8B; text-decoration: none;">[paper]</a> <a href="https://github.com/teang1995/DMM" style="color: #009B8B; text-decoration: none;">[code]</a> \\
Junhyuk So\*, YongTaek Lim\*, Yewon Kim\*, <u>Changdae Oh</u>, Kyungwoo Song \\
<span style="color: #3700FF">**IEEE Access**</span> 2023 -->

- **BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning** \\
<a href="https://arxiv.org/abs/2303.14773" style="color: #009B8B; text-decoration: none;">[paper]</a> <a href="https://github.com/changdaeoh/BlackVIP" style="color: #009B8B; text-decoration: none;">[code]</a> \\
<u>Changdae Oh</u>, Hyeji Hwang, Hee-young Lee, YongTaek Lim, Geunyoung Jung, Jiyoung Jung, Hosik Choi, Kyungwoo Song \\
<span style="color:darkred">**CVPR**</span> 2023

- **Learning Fair Representation via Distributional Contrastive Disentanglement** \\
<a href="https://dl.acm.org/doi/abs/10.1145/3534678.3539232" style="color: #009B8B; text-decoration: none;">[paper]</a> 
<a href="https://github.com/changdaeoh/FarconVAE" style="color: #009B8B; text-decoration: none;">[code]</a> \\
<u>Changdae Oh</u>, Heeji Won, Junhyuk So, Taero Kim, Yewon Kim, Hosik Choi, Kyungwoo Song \\
<span style="color:darkred">**KDD**</span> 2022

<!-- ## Publication (Domestic)
- **Pre-trained Models Ensembling for Domain Generalization in Chemistry Classification** \\
Jinho Kang, Taero Kim, Yewon Kim, <u>Changdae Oh</u>, Jiyoung Jung, Rakwoo Chang, Kyungwoo Song \\
CKAIA 2023 -->

<!--   , <span style="color:red">_Spotlight Presentation_</span> (acceptance = 176 / 3391 = 5.1%)  -->

<!-- ## Domestic Conference Publication

## Workshop Publication
 -->

<!-- ## Preprints

- **Robust Adaptation of Foundation Models with Black-Box Visual Prompting** \\
<u>Changdae Oh</u>, Gyeongdeok Seo, Geunyoung Jung, Zhi-Qi Cheng, Hosik Choi, Jiyoung Jung, Kyungwoo Song \\
<a href="https://arxiv.org/pdf/2407.17491" style="color: #009B8B; text-decoration: none;">[paper]</a> \\
2024

- **Enhancing Temporal Action Localization: Advanced S6 Modeling with Recurrent Mechanism** \\
Sangyoun Lee, Juho Jung, <u>Changdae Oh</u>, Sunghee Yun \\
<a href="https://arxiv.org/abs/2407.13078" style="color: #009B8B; text-decoration: none;">[paper]</a> \\
2024

<!-- - **Multimodal Learning for Social Event Analysis** \\
<u>Changdae Oh</u>, Hoyoon Byun, Minhoi Park, YongTaek Lim, Neil Kim, Kyungwoo Song -->

<!-- - **Multi-purpose Technology Commercialization Recommender System with Large-scale Korean Language Model** \\
Hyeji Hwang\*, YongTaek Lim\*, <u>Changdae Oh</u>\*, Seungyeon Kim, Eunkyeong Lee, Yunjeong Choi, Sungjin Kim, Hosik Choi, Kyungwoo Song -->

<!-- - **Graph Perceiver IO: A General Architecture for Graph Structured Data** \\
Seyun Bae, Hoyoon Byun, <u>Changdae Oh</u>, Yoon-Sik Cho, Kyungwoo Song \\
<a href="https://arxiv.org/abs/2209.06418" style="color: #009B8B; text-decoration: none;">[paper]</a> \\
2022 -->

## Education
- **Ph.D.** in Computer Science, <a href="https://www.cs.wisc.edu/" style="color: #009B8B; text-decoration: none;">**University of Wisconsin-Madison**</a> \\
advisor: Prof. <a href="https://pages.cs.wisc.edu/~sharonli/" style="color: #009B8B; text-decoration:none">**Sharon Li**</a> \\
Sep. 2024 ~ Present

- **M.S.** in Artificial Intelligence, <a href="https://english.uos.ac.kr/" style="color: #009B8B; text-decoration: none;">**University of Seoul**</a> \\
advisor: Prof. <a href="https://scholar.google.com/citations?user=HWxRii4AAAAJ&hl=ko&oi=ao" style="color: #009B8B; text-decoration:none">**Kyungwoo Song**</a> and Prof. <a href="https://scholar.google.com/citations?user=wc_MQkoAAAAJ&hl=ko&oi=ao" style="color: #009B8B; text-decoration:none">**Jiyoung Jung**</a> \\
Mar. 2022 - Aug. 2024

- **B.S.** in Statistics, <a href="https://english.uos.ac.kr/" style="color: #009B8B; text-decoration: none;">**University of Seoul**</a> \\
Mar. 2016 - Feb. 2022

## Experience
* *Research Scientist Intern*, **Meta Superintelligence Labs** \\
Mentor: <a href="https://jkatzsam.github.io/" style="color: #009B8B; text-decoration:none">**Julian Katz-Samuels**</a>, May. 2026 ~ current
* *Visiting Student-Subcontractor*, **Argonne National Laboratory** \\
Mentor: <a href="https://tanwimallick.github.io/" style="color: #009B8B; text-decoration:none">**Tanwi Mallick**</a>, Feb. 2026 ~ current
* *Research Intern*, **NAVER AI Lab** \\
Mentor: <a href="https://scholar.google.com/citations?user=jcP7m1QAAAAJ&hl=en" style="color: #009B8B; text-decoration:none">**Dongyoon Han**</a> and <a href="https://scholar.google.com/citations?user=o0qtjzYAAAAJ&hl=en" style="color: #009B8B; text-decoration:none">**Sangdoo Yun**</a>, Apr. 2023 ~ Aug. 2024
  * DaWin: Training-free Dynamic Weight Interpolation for Robust Adaptation, ICLR 2025
* *Visiting Scholar*, **Carnegie Mellon University** \\
Mentor:  <a href="https://zhiqic.github.io/homepage/index.html" style="color: #009B8B; text-decoration:none">**Zhi-Qi Cheng**</a>, Sep. 2023 ~ Feb. 2024 \\
  * Towards Calibrated Robust Fine-Tuning of Vision-Language Model, NeurIPS 2024
  * Mitigating the Linguistic Gap with Phonemic Representations for Robust Cross-lingual Transfer, EMNLP 2024 Workshop

## Talks
- Jan. 2026, MLAI Lab @ Yonsei University, "*On the Dynamic Reliability of Adaptive Foundation Models*"
- Jun. 2025, <a href="https://researchtrend.ai/" style="color: #009B8B; text-decoration:none">ResearchTrend.AI</a>, "*Visual Instruction Bottleneck Tuning*"

<!-- ## Projects
### Carnegie Mellon University
- Robust Fine-Tuning of Visual Foundation Models
  - <a href="https://zhiqic.github.io/CMU-2023-Fall-11-775-MultimediaAnalysis/index.html" style="color: #009B8B; text-decoration: none;">Large-Scale Multimedia Analysis 11-775 2023f</a> Course Project, Sep. 2023 - Dec. 2023
  - *related papers: <a href="https://arxiv.org/abs/2311.01723" style="color: #009B8B; text-decoration: none;">Towards Calibrated Robust Fine-Tuning of Vision-Language Models</a> (NeurIPS 2023 Workshop DistShift)*
- Delving into the Feature Distortion Effect of Fine-Tuned Visual Foundation Models
  - <a href="https://deeplearning.cs.cmu.edu/F23/index.html" style="color: #009B8B; text-decoration: none;">Introduction to Deep Learning 11-785 2023f</a> Course Project, Sep. 2023 - Dec. 2023
- Exploring Prompt Engineering for RNN-based Language Models
  - <a href="" style="color: #009B8B; text-decoration: none;">Natural Language Processing 11-411/611 2023f</a> Course Project, Sep. 2023 - Dec. 2023
- AI on the Edge with Robotics (AIER)
  - <a href="https://execed.isri.cmu.edu/" style="color: #009B8B; text-decoration: none;">Executive & Professional Education Program at S3D</a>, Oct. 2023 - present
  - *repository: <a href="https://github.com/IITP-CMU23-aespa/Photograbot" style="color: #009B8B; text-decoration: none;">Photograbot</a>*
   
### University of Seoul
- Education Contents Relationship Analysis with Multimodal Learning
  - <a href="http://www.jointips.or.kr/about_en.php" style="color: #009B8B; text-decoration: none;">TIPS</a>, Dec. 2022 - Aug. 2023
  - *related papers: <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417424008261" style="color: #009B8B; text-decoration: none;">Language Model-guided Student Performance Prediction with Multimodal Auxiliary Information</a>*
- Multimodal Learning for Social Event Analysis
  - <a href="https://hustlers.oopy.io/" style="color: #009B8B; text-decoration: none;">HUSTLERS Corp.</a>, Oct. 2022 - Dec. 2022
  - *related papers: Multimodal Learning for Social Event Analysis (preprint)*
- Multi-purpose Technology Commercialization Documents Recommendation
  - <a href="https://www.kisti.re.kr/eng/" style="color: #009B8B; text-decoration: none;">KISTI</a>, Mar. 2022 - Nov. 2022
  - *related papers: Multi-purpose Technology Commercialization Recommender System with Large-scale Korean Language Model (preprint)*
- Epidemiological Relevance Evaluation Technology for Vaccination Reactions
  - <a href="https://www.mfds.go.kr/eng/index.do" style="color: #009B8B; text-decoration: none;">Ministry of Food and Drug Safety</a>, Mar. 2022 - Aug. 2023
- Keyword Extraction for Technology Commercialization Documents
  - <a href="https://www.kisti.re.kr/eng/" style="color: #009B8B; text-decoration: none;">KISTI</a>, June. 2021 - Oct. 2021
  - *related papers: TC-BERT: Large-scale Language Model for Korean Technology Documents (preprint)* -->

<!-- ## Awards & Scholarships
- **DEI Scholarship Travel Awards**, CVPR, Apr. 2023
- (Scholarship; USD 41K) **AI Intensive Program at Carnegie Mellon University**, IITP and Sogang University, Mar. 2023 
- (1st place) **Outstanding Paper Award, President's prize**, University of Seoul, Feb. 2023
- (2nd place) **Presentation Award, Workshop on Data-Driven Chemicals Management**, University of Seoul, Feb. 2023
- **Student Travel Awards**, KDD, Jul. 2022 
- **Academic Excellence Scholarship (half-tuition)**, University of Seoul, Feb. 2021
- **Academic Excellence Scholarship (half-tuition)**, University of Seoul, Aug. 2020 -->

## Academic Services 
- Conference Reviewer:
  - NeurIPS 2025, 2024
  - ICML 2026, 2025 (**Top Reviewer**)
  - ICLR 2026, 2025
  - AAAI 2025
  - AISTATS 2026
  - CVPR 2024
- Conference Volunteer: NeurIPS'24, KDD'22
- Workshop Committee
  - NeurIPS 2025,  <a href="https://reliablemlworkshop.github.io/" style="color: #009B8B; text-decoration:none">Reliable ML from Unreliable Data</a>
  - ICLR 2025,  <a href="https://uncertainty-foundation-models.github.io/" style="color: #009B8B; text-decoration:none">Quantify Uncertainty and Hallucination in Foundation Models: The Next Frontier in Reliable AI</a>
- Journal Reviewer: TMLR, Neural Network
